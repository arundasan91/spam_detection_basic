{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC SPAM DETECTION USING MACHINE LEARNING\n",
    "\n",
    "**Arun Das**    \n",
    "Research Fellow,    \n",
    "Open Cloud Institute,    \n",
    "The University of Texas at San Antonio.    \n",
    "arun.das@my.utsa.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M**achine Learning (ML) is a wonderful field of Computer Science which evolved to something greater recently. The buzzword `machine learning` and `deep learning` now rhymes well with `artificial intelligence` the once sci-fi technology. It is now impacting us in a way never imagined and is slowly being integrated in to our everyday lives. Take for example your go-to assistant Google Now or Siri. The brain of these personal assistants are very complex neural networks and other software crafted specifically for the task of answering your queries.\n",
    "Here, we tackle a basic machine learning problem of classifying emails as Spam or Not Spam. We will use a publically available, clean and labelled dataset for the same. To be comprehensive, we will train our model over various classifiers and pick the best of out it. Moving forward in future work, we will do data mining to get our own email data and train a classifier to do spam detection. For now, let's see the simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, let us import some libraries.\n",
    "\n",
    "# Import Pandas to manage data\n",
    "import pandas as pd\n",
    "\n",
    "# Import Numpy to manage numerical data, matrices etc.\n",
    "import numpy as np\n",
    "\n",
    "# Import Matplotlib for visualizing graphs, charts, etc.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import OrderedDict to get extra features of Python Dictionaries.\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Import different classifiers from Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the data to local machine from this URL: http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/    \n",
    "\n",
    "*A bit about the dataset*: (extracted from http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.DOCUMENTATION)\n",
    "\n",
    "**Number of Instances**: 4601 (1813 Spam = 39.4%)    \n",
    "\n",
    "**Number of Attributes**: 58 (57 continuous, 1 nominal class label)    \n",
    " \n",
    "**Attribute Information**:\n",
    "The last column of 'spambase.data' denotes whether the e-mail was \n",
    "considered spam (1) or not (0), i.e. unsolicited commercial e-mail.      \n",
    "Most of the attributes indicate whether a particular word or\n",
    "character was frequently occuring in the e-mail.  The run-length\n",
    "attributes (55-57) measure the length of sequences of consecutive \n",
    "capital letters.  For the statistical measures of each attribute, \n",
    "see the end of this file.  Here are the definitions of the attributes:    \n",
    "\n",
    "*48 continuous real [0,100]* attributes of type word_freq_WORD = percentage of words in the e-mail that match WORD,\n",
    "i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.    \n",
    "\n",
    "*6 continuous real [0,100]* attributes of type char_freq_CHAR = percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail    \n",
    "\n",
    "*1 continuous real [1,...]* attribute of type capital_run_length_average = average length of uninterrupted sequences of capital letters    \n",
    "\n",
    "*1 continuous integer [1,...]* attribute of type capital_run_length_longest = length of longest uninterrupted sequence of capital letters    \n",
    "    \n",
    "*1 continuous integer [1,...]* attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail      \n",
    "\n",
    "*1 nominal {0,1}* class attribute of type spam = denotes whether the e-mail was considered spam (1) or not (0),     \n",
    "i.e. unsolicited commercial e-mail.      \n",
    "    \n",
    "**Missing Attribute Values**: None    \n",
    "\n",
    "**Class Distribution**:     \n",
    "\tSpam\t  1813  (39.4%)     \n",
    "\tNon-Spam  2788  (60.6%)    \n",
    "\n",
    "A bit more information regarding the different features is available [here](https://github.com/WinVector/zmPDSwR/tree/master/Spambase). The different features are:\n",
    "   *'word.freq.make', 'word.freq.address', 'word.freq.all',\n",
    "   'word.freq.3d', 'word.freq.our', 'word.freq.over', 'word.freq.remove',\n",
    "   'word.freq.internet', 'word.freq.order', 'word.freq.mail',\n",
    "   'word.freq.receive', 'word.freq.will', 'word.freq.people',\n",
    "   'word.freq.report', 'word.freq.addresses', 'word.freq.free',\n",
    "   'word.freq.business', 'word.freq.email', 'word.freq.you',\n",
    "   'word.freq.credit', 'word.freq.your', 'word.freq.font',\n",
    "   'word.freq.000', 'word.freq.money', 'word.freq.hp', 'word.freq.hpl',\n",
    "   'word.freq.george', 'word.freq.650', 'word.freq.lab',\n",
    "   'word.freq.labs', 'word.freq.telnet', 'word.freq.857',\n",
    "   'word.freq.data', 'word.freq.415', 'word.freq.85',\n",
    "   'word.freq.technology', 'word.freq.1999', 'word.freq.parts',\n",
    "   'word.freq.pm', 'word.freq.direct', 'word.freq.cs',\n",
    "   'word.freq.meeting', 'word.freq.original', 'word.freq.project',\n",
    "   'word.freq.re', 'word.freq.edu', 'word.freq.table',\n",
    "   'word.freq.conference', 'char.freq.semi', 'char.freq.lparen',\n",
    "   'char.freq.lbrack', 'char.freq.bang', 'char.freq.dollar',\n",
    "   'char.freq.hash', 'capital.run.length.average',\n",
    "   'capital.run.length.longest', 'capital.run.length.total',\n",
    "   'spam'.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (2760, 57)\n",
      "y_train.shape: (2760,)\n",
      "X_test.shape: (1840, 57)\n",
      "y_test.shape: (1840,)\n"
     ]
    }
   ],
   "source": [
    "# Read the data using pandas\n",
    "data = pd.read_csv('spambase.data').as_matrix()\n",
    "\n",
    "# Shuffle the dataset\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Data has 58 columns altogether, the last column being the labels.\n",
    "# Extract the features and target seperately\n",
    "X = data[:,:57]\n",
    "y = data[:,-1]\n",
    "\n",
    "# Split the data into train and test. The ratio here is 60/40 (train/test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "# Print the shapes of the train and test data\n",
    "print \"X_train.shape: {}\" .format(X_train.shape)\n",
    "print \"y_train.shape: {}\" .format(y_train.shape)\n",
    "print \"X_test.shape: {}\" .format(X_test.shape)\n",
    "print \"y_test.shape: {}\" .format(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Nearest Neighbors classifier\n",
      "Training Linear SVM classifier\n",
      "Training RBF SVM classifier\n",
      "Training Gaussian Process classifier\n",
      "Training Decision Tree classifier\n",
      "Training Random Forest classifier\n",
      "Training Neural Net classifier\n",
      "Training AdaBoost classifier\n",
      "Training Naive Bayes classifier\n",
      "Training QDA classifier\n",
      "\n",
      "Training complete\n",
      "Results:\n",
      "\n",
      "Classifier: AdaBoost, \tScore: 0.932608695652\n",
      "Classifier: Linear SVM, \tScore: 0.917391304348\n",
      "Classifier: Decision Tree, \tScore: 0.909782608696\n",
      "Classifier: Neural Net, \tScore: 0.870108695652\n",
      "Classifier: Random Forest, \tScore: 0.858695652174\n",
      "Classifier: Naive Bayes, \tScore: 0.828260869565\n",
      "Classifier: QDA, \tScore: 0.825\n",
      "Classifier: Nearest Neighbors, \tScore: 0.786413043478\n",
      "Classifier: RBF SVM, \tScore: 0.689130434783\n",
      "Classifier: Gaussian Process, \tScore: 0.598913043478\n"
     ]
    }
   ],
   "source": [
    "# A dictionary to store the classifiers and respective scores\n",
    "score_dict = {}\n",
    "\n",
    "# Different classifiers used in the training procedure and their initializations\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# Variable to store the number of classifiers\n",
    "num_classifiers = len(classifiers)\n",
    "\n",
    "# Names of the classifiers (string)\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "# Training loop (iterates over each classifiers and trains a model based on them)\n",
    "for num, classifier in enumerate(classifiers):\n",
    "    model = classifier # Current classifier\n",
    "    model.fit(X_train, y_train) # Fit the current classifier with the training data\n",
    "    score = model.score(X_test, y_test) # Assess the performance of the trained model using test data\n",
    "    name_of_classifer = names[num] \n",
    "    print \"Training {} classifier\" .format(name_of_classifer)\n",
    "    #print \"Score for {} :\" .format(name_of_classifer), score\n",
    "    score_dict[name_of_classifer] = score # Save the classifier and score information\n",
    "\n",
    "# Display the classifier and score information, sorted, starting with the best classifier.\n",
    "score_dict_sorted_by_value = OrderedDict(sorted(score_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "print \"\\nTraining complete\\nResults:\\n\"\n",
    "for k,v in score_dict_sorted_by_value.items():\n",
    "    print \"Classifier: {}, \\tScore: {}\" .format(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great our models learned pretty well across the many features. We could also reduce the dimensions to \"word: frequency alone. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. For that, change `X = data[:,:57]` to `X = data[:,:48]` so that variable `X` will hold only the respective columns corresponding to word data.    \n",
    "We can add much more to this. Let us dig deep in future tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
